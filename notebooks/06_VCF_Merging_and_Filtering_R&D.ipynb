{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30bdf85b-ac17-4018-82c8-6aefb72dff84",
   "metadata": {},
   "source": [
    "#  STEP 5: VCF Merging and Filtering (Phase 7 R&D)\n",
    "\n",
    "**Goal:** Combine all 93 high-quality VCF files into a single \"master\" VCF, and then filter this file for high-confidence SNPs.\n",
    "\n",
    "**Why (The \"Handoff\" to the Tree):**\n",
    "This is the final step before building the phylogenetic tree (Goal 1).\n",
    "1.  **Merging:** We cannot build one tree from 93 different files. We must merge them into a single \"matrix\" file using `bcftools merge`.\n",
    "2.  **Filtering (R&D):** The \"master\" VCF will contain *all* variants (SNPs). We must develop an R&D recipe (`bcftools filter`) to select *only* the high-quality SNPs (e.g., `QUAL > 30`) that we trust for building our tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096d943f-43da-4591-b383-2a68699a1410",
   "metadata": {},
   "source": [
    "## 1: Handoff from \"The Factory\" (Phase 6 Success)\n",
    "\n",
    "**The Handoff (Done):**\n",
    "We successfully updated our `Snakefile` (V5.0) to use the 93-sample \"clean cohort\" (`metadata_final_cohort.csv`) and the correct haploid recipe (`bcftools call --ploidy 1`).\n",
    "\n",
    "We then executed the high-throughput job from the terminal:\n",
    "\n",
    "```bash\n",
    "snakemake --cores 8 --rerun-triggers mtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4244f440-ccb7-48c9-bebe-6e6f493b8559",
   "metadata": {},
   "source": [
    "## STEP 2: R&D Test (Merging 93 VCFs)\n",
    "\n",
    "**Goal:** Test the `bcftools merge` command to combine all 93 high-quality VCFs into one \"Master VCF\".\n",
    "\n",
    "**Why (The \"Recipe\"):**\n",
    "We cannot pass 93 file names to the command line. The \"clean\" (and fast) way to do this is a two-part recipe:\n",
    "1.  **Generate a List:** We will use `pandas` to read our 93-sample \"brain\" (`metadata_final_cohort.csv`) and generate a simple text file that lists the *paths* to all 93 `.vcf.gz` files.\n",
    "2.  **Run the Merge:** We will then use the `-l` flag (`bcftools merge -l [file_list]`) to merge them all in one efficient operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02442846-f4e8-448f-8864-1b3efec45fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 2.A: Generating the file list (the 'input') ---\n",
      "Loading the 93-sample 'brain' from: ../results/metadata/metadata_final_cohort.csv\n",
      "Generated 93 paths for the merge list.\n",
      "SUCCESS: Created (and OVERWROTE): ../results/variant_calling/vcf_list_for_merge.txt\n",
      "--- Verification (first 5 files in list - Correct for Factory): ---\n",
      "results/variant_calling/PA097.vcf.gz\n",
      "results/variant_calling/PA096.vcf.gz\n",
      "results/variant_calling/PA095.vcf.gz\n",
      "results/variant_calling/PA093.vcf.gz\n",
      "results/variant_calling/PA092.vcf.gz\n",
      "\n",
      "--- STEP 2.B: Running the Merge (The R&D Simulation) ---\n",
      "Starting merge... (This should be fast, ~1 min)\n",
      "\n",
      "Merge complete.\n",
      "\n",
      "--- Verification: Checking for 'Master VCF' file ---\n",
      "-rw-rw-r-- 1 refm_youssef refm_youssef 16M Nov  1 20:50 ../results/variant_calling/MASTER_MERGED.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"--- STEP 2.A: Generating the file list (the 'input') ---\")\n",
    "\n",
    "# --- 1. Define Paths ---\n",
    "cohort_file = \"../results/metadata/metadata_final_cohort.csv\"\n",
    "vcf_dir_relative_to_notebook = \"../results/variant_calling\"\n",
    "list_file_out = f\"{vcf_dir_relative_to_notebook}/vcf_list_for_merge.txt\"\n",
    "\n",
    "# --- [UNCHANGED] The list paths *must* be relative to the PROJECT ROOT\n",
    "vcf_dir_relative_to_root = \"results/variant_calling\"\n",
    "\n",
    "# --- 2. Load the 93-sample \"Brain\" ---\n",
    "print(f\"Loading the 93-sample 'brain' from: {cohort_file}\")\n",
    "df_clean = pd.read_csv(cohort_file)\n",
    "\n",
    "# --- 3. Create the list of *CORRECT* (Root-Relative) paths ---\n",
    "vcf_files_list = [f\"{vcf_dir_relative_to_root}/{sample_id}.vcf.gz\" for sample_id in df_clean['sample_id']]\n",
    "print(f\"Generated {len(vcf_files_list)} paths for the merge list.\")\n",
    "\n",
    "# --- 4. Save the list to the text file (The \"Handoff\") ---\n",
    "with open(list_file_out, 'w') as f:\n",
    "    for path in vcf_files_list:\n",
    "        f.write(f\"{path}\\n\")\n",
    "\n",
    "print(f\"SUCCESS: Created (and OVERWROTE): {list_file_out}\")\n",
    "print(\"--- Verification (first 5 files in list - Correct for Factory): ---\")\n",
    "!head -n 5 {list_file_out}\n",
    "\n",
    "print(\"\\n--- STEP 2.B: Running the Merge (The R&D Simulation) ---\")\n",
    "\n",
    "# --- 5. Define the Merge \"Recipe\" ---\n",
    "# (Paths *relative to the root* for the command)\n",
    "list_file_for_root = \"results/variant_calling/vcf_list_for_merge.txt\"\n",
    "master_vcf_for_root = \"results/variant_calling/MASTER_MERGED.vcf.gz\"\n",
    "\n",
    "# --- [THE FIX (Rule 4)] ---\n",
    "# We \"simulate\" the Factory's CWD by using (cd ../ && ...)\n",
    "# This tells the shell: \"1. Go to the root. 2. Run bcftools from there.\"\n",
    "command = f\"(cd ../ && bcftools merge -l {list_file_for_root} -O z -o {master_vcf_for_root})\"\n",
    "\n",
    "print(\"Starting merge... (This should be fast, ~1 min)\")\n",
    "\n",
    "# --- 6. Run the R&D Test ---\n",
    "!{command}\n",
    "\n",
    "print(\"\\nMerge complete.\")\n",
    "\n",
    "# --- 7. Verification (The Proof) ---\n",
    "# (We check the file using the *notebook's* relative path)\n",
    "print(f\"\\n--- Verification: Checking for 'Master VCF' file ---\")\n",
    "!ls -lh {vcf_dir_relative_to_notebook}/MASTER_MERGED.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cbf242-0494-478b-a472-1fb9de98022f",
   "metadata": {},
   "source": [
    "##  3: R&D Test (Filtering the Master VCF)\n",
    "\n",
    "**Goal:** Filter the `MASTER_MERGED.vcf.gz` to create a final, \"analysis-ready\" VCF.\n",
    "\n",
    "**Why (The \"Recipe\"):**\n",
    "The 16M Master VCF contains *all* variants (SNPs, INDELs, low-quality calls). For a clean phylogenetic analysis (Goal 1), we must create a final file that contains *only* high-confidence, bi-allelic SNPs.\n",
    "\n",
    "**R&D Test:**\n",
    "We will use `bcftools view` to apply two critical filters:\n",
    "1.  `TYPE==\"snp\"`: This keeps *only* SNPs and removes all INDELs.\n",
    "2.  `QUAL > 30`: This keeps *only* \"High-Quality\" calls (a standard threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62cae7e-67b9-4ea1-8806-4bc104f74ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 3: Filtering the Master VCF for high-quality SNPs ---\n",
      "Starting filter... (This should be very fast)\n",
      "\n",
      "Filter complete.\n",
      "\n",
      "--- Verification: Checking for 'Analysis-Ready VCF' file ---\n",
      "-rw-rw-r-- 1 refm_youssef refm_youssef 15M Nov  1 20:54 ../results/variant_calling/ANALYSIS_READY.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"--- STEP 3: Filtering the Master VCF for high-quality SNPs ---\")\n",
    "\n",
    "# --- 1. Define Paths (Relative to 'notebooks/' CWD) ---\n",
    "vcf_dir = \"../results/variant_calling\"\n",
    "input_vcf = f\"{vcf_dir}/MASTER_MERGED.vcf.gz\"\n",
    "\n",
    "# This is our \"FINAL\" VCF file for the whole project!\n",
    "output_vcf = f\"{vcf_dir}/ANALYSIS_READY.vcf.gz\"\n",
    "\n",
    "# --- 2. Build the Filter \"Recipe\" ---\n",
    "# -i : \"include\" only sites that match this expression\n",
    "# 'TYPE==\"snp\" & QUAL > 30' : The filter logic\n",
    "# -O z : Output compressed .gz\n",
    "# -o : Output file\n",
    "command = f\"bcftools view -i 'TYPE==\\\"snp\\\" & QUAL > 30' -O z -o {output_vcf} {input_vcf}\"\n",
    "\n",
    "print(f\"Starting filter... (This should be very fast)\")\n",
    "\n",
    "# --- 3. Run the R&D Test ---\n",
    "!{command}\n",
    "\n",
    "print(\"\\nFilter complete.\")\n",
    "\n",
    "# --- 4. Verification (The Proof) ---\n",
    "print(f\"\\n--- Verification: Checking for 'Analysis-Ready VCF' file ---\")\n",
    "!ls -lh {output_vcf}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936affa-989f-4ebe-aef2-9cf1c9133f92",
   "metadata": {},
   "source": [
    "## Conclusion & Handoff to \"The Factory\"\n",
    "\n",
    "**Status:** Success. The R&D for the *entire* Variant Calling pipeline (Phase 1-7) is 100% complete.\n",
    "\n",
    "**Our Achievements (The \"Recipes\"):**\n",
    "We have now developed and tested *all* the recipes needed for our pipeline:\n",
    "1.  **Merge Recipe:** We successfully tested the `bcftools merge -l [list_file]` command, creating `MASTER_MERGED.vcf.gz` (16M).\n",
    "2.  **Filter Recipe:** We successfully tested the `bcftools view -i '...'` command, creating our final, clean `ANALYSIS_READY.vcf.gz` (15M).\n",
    "\n",
    "**Next Step (The Handoff):**\n",
    "This notebook (`06_...ipynb`) is now complete. We will save it, and our new recipe file (`vcf_list_for_merge.txt`), to GitHub (Rule 5).\n",
    "\n",
    "We are ready to automate these new recipes in our main `Snakefile` (V6.0)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
